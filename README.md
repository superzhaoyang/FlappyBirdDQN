# Project intro

&nbsp;&nbsp;&nbsp;&nbsp;This project uses the main framework of pytorch+pygame+opencv,Papers on Deepmind《Human-level control through deep Reinforcement learning》,Choosing Flappy Bird as a game instance to reproduce its core algorithm.As we finish trainging,this brid can beat most of people players.

![Human-level control through deep Reinforcement learning](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/%E6%89%B9%E6%B3%A8%202020-05-13%20194059.png)
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;《Human-level control through deep Reinforcement learning》
<br> <br> <br>
 ![project cover](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202020-11-01%20221144.png)
 <br> <br> 

![DQN VS traditional machine learnign algorithms](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/QQ%E5%9B%BE%E7%89%8720200421145125.png)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AS we can see,DQN(blue)'s performance is better than traditional machine learning algorithms.
=======

# Project video and image

![](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/YMzFFf.png)

# Project structure

![net train structure](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/%E6%89%B9%E6%B3%A8%202020-04-19%20122736.png)

![overrall structure](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/%E6%89%B9%E6%B3%A8%202020-04-19%20122746.png)

# Reinforcement Learning five Elements

![](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/%E6%89%B9%E6%B3%A8%202020-05-12%20222447.png)

# Deep Q network

![](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/new2.png)

# Explanation of file or folder
final_log_file.txt :this txt file records the detail step 's state of the bird;  
score.txt this txt :file records the scores of the flappy bird every 1000 steps;  
score.txt this txt :records the socres of the flappy bird afters 5390000 iterations;  
assets :this foler records the source files of the Game Flappy Bird;  
saving_nets2:this folder records the last few tiemes models;  
# Data Analysze
![](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/290000%20steps.png)  
the avg scores of 2900000 iterations.  
==
![](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/5300000.png)  
the avg scores of 5300000 iterations.as we can see ,there is a obvious score growth about 3000000 iterations.Clearly,there is no doubt that the score will continuely grow if we add the training iterations. 
==
![](https://github.com/superzhaoyang/img_storage/blob/master/FlappyBird/avg%20score.png)    
At point ot 5300000 ,the avg scores and the peak score of the bird.  
==

